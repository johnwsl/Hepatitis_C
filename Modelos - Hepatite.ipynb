{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9533c8ce",
   "metadata": {},
   "source": [
    "# Modelos de Classificação - Hepatite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "976d1b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas de manipualção e visualização de dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from mlxtend.plotting import plot_decision_regions\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "\n",
    "# Classes dos modelo\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier as knn\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from mord import LogisticAT\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Essemble\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Funções de avaliação dos modelos\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, roc_auc_score, plot_confusion_matrix, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from yellowbrick.classifier import ROCAUC\n",
    "\n",
    "#SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#PerC\n",
    "from perc.src.data.build_dataset import build, normalize\n",
    "from perc.src.model.classification.perturbation import PerC_Mean, PerC_Covariance, PerC\n",
    "\n",
    "# Seleção de Features e redução de dimencionalidade\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1144b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset sem outliers\n",
    "df_hepatite = pd.read_csv('HCV-Data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c76e488",
   "metadata": {},
   "source": [
    "A remoção de outliers mostrou-se eficiente na performace do modelo aumentando em serca de 1% a acurácia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cb0768c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Age</th>\n",
       "      <th>ALB</th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>BIL</th>\n",
       "      <th>CHE</th>\n",
       "      <th>CHOL</th>\n",
       "      <th>CREA</th>\n",
       "      <th>GGT</th>\n",
       "      <th>PROT</th>\n",
       "      <th>M</th>\n",
       "      <th>F</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.531488</td>\n",
       "      <td>-0.614892</td>\n",
       "      <td>-0.613672</td>\n",
       "      <td>-0.938676</td>\n",
       "      <td>-0.376413</td>\n",
       "      <td>-0.201172</td>\n",
       "      <td>-0.588422</td>\n",
       "      <td>-1.935993</td>\n",
       "      <td>0.492894</td>\n",
       "      <td>-0.503635</td>\n",
       "      <td>-0.660649</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.531488</td>\n",
       "      <td>-0.614892</td>\n",
       "      <td>0.101811</td>\n",
       "      <td>-0.452676</td>\n",
       "      <td>-0.296648</td>\n",
       "      <td>-0.383411</td>\n",
       "      <td>1.368547</td>\n",
       "      <td>-0.520644</td>\n",
       "      <td>-0.151232</td>\n",
       "      <td>-0.436211</td>\n",
       "      <td>0.862461</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.531488</td>\n",
       "      <td>0.941291</td>\n",
       "      <td>0.278672</td>\n",
       "      <td>0.406081</td>\n",
       "      <td>0.559296</td>\n",
       "      <td>-0.272043</td>\n",
       "      <td>0.293137</td>\n",
       "      <td>-0.160045</td>\n",
       "      <td>0.090315</td>\n",
       "      <td>-0.097166</td>\n",
       "      <td>1.431089</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-1.531488</td>\n",
       "      <td>0.255829</td>\n",
       "      <td>-0.633770</td>\n",
       "      <td>0.141848</td>\n",
       "      <td>-0.361073</td>\n",
       "      <td>0.375918</td>\n",
       "      <td>-0.403803</td>\n",
       "      <td>-0.574734</td>\n",
       "      <td>-0.030458</td>\n",
       "      <td>-0.085607</td>\n",
       "      <td>0.699996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.531488</td>\n",
       "      <td>-0.485210</td>\n",
       "      <td>0.254555</td>\n",
       "      <td>0.236217</td>\n",
       "      <td>-0.293580</td>\n",
       "      <td>-0.094866</td>\n",
       "      <td>0.436217</td>\n",
       "      <td>-0.953362</td>\n",
       "      <td>-0.110974</td>\n",
       "      <td>-0.160737</td>\n",
       "      <td>-0.721574</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       Age       ALB       ALP       ALT       AST       BIL  \\\n",
       "0           0 -1.531488 -0.614892 -0.613672 -0.938676 -0.376413 -0.201172   \n",
       "1           1 -1.531488 -0.614892  0.101811 -0.452676 -0.296648 -0.383411   \n",
       "2           2 -1.531488  0.941291  0.278672  0.406081  0.559296 -0.272043   \n",
       "3           3 -1.531488  0.255829 -0.633770  0.141848 -0.361073  0.375918   \n",
       "4           4 -1.531488 -0.485210  0.254555  0.236217 -0.293580 -0.094866   \n",
       "\n",
       "        CHE      CHOL      CREA       GGT      PROT    M    F  Category  \n",
       "0 -0.588422 -1.935993  0.492894 -0.503635 -0.660649  1.0  0.0         0  \n",
       "1  1.368547 -0.520644 -0.151232 -0.436211  0.862461  1.0  0.0         0  \n",
       "2  0.293137 -0.160045  0.090315 -0.097166  1.431089  1.0  0.0         0  \n",
       "3 -0.403803 -0.574734 -0.030458 -0.085607  0.699996  1.0  0.0         0  \n",
       "4  0.436217 -0.953362 -0.110974 -0.160737 -0.721574  1.0  0.0         0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hepatite.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31fde9e",
   "metadata": {},
   "source": [
    "Ao exportar o dataset sem outliers surgiu a coluna `Unnamed: 0` que será removida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc3afbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hepatite.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f78bc7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 608 entries, 0 to 607\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Age       608 non-null    float64\n",
      " 1   ALB       608 non-null    float64\n",
      " 2   ALP       608 non-null    float64\n",
      " 3   ALT       608 non-null    float64\n",
      " 4   AST       608 non-null    float64\n",
      " 5   BIL       608 non-null    float64\n",
      " 6   CHE       608 non-null    float64\n",
      " 7   CHOL      608 non-null    float64\n",
      " 8   CREA      608 non-null    float64\n",
      " 9   GGT       608 non-null    float64\n",
      " 10  PROT      608 non-null    float64\n",
      " 11  M         608 non-null    float64\n",
      " 12  F         608 non-null    float64\n",
      " 13  Category  608 non-null    int64  \n",
      "dtypes: float64(13), int64(1)\n",
      "memory usage: 66.6 KB\n"
     ]
    }
   ],
   "source": [
    "df_hepatite.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46a40e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_hepatite['Category'] = df_hepatite['Category'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b6b44fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 608 entries, 0 to 607\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Age       608 non-null    float64\n",
      " 1   ALB       608 non-null    float64\n",
      " 2   ALP       608 non-null    float64\n",
      " 3   ALT       608 non-null    float64\n",
      " 4   AST       608 non-null    float64\n",
      " 5   BIL       608 non-null    float64\n",
      " 6   CHE       608 non-null    float64\n",
      " 7   CHOL      608 non-null    float64\n",
      " 8   CREA      608 non-null    float64\n",
      " 9   GGT       608 non-null    float64\n",
      " 10  PROT      608 non-null    float64\n",
      " 11  M         608 non-null    float64\n",
      " 12  F         608 non-null    float64\n",
      " 13  Category  608 non-null    int64  \n",
      "dtypes: float64(13), int64(1)\n",
      "memory usage: 66.6 KB\n"
     ]
    }
   ],
   "source": [
    "df_hepatite.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3da92224",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_hepatite.drop('Category', axis=1)\n",
    "y = df_hepatite['Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1e44c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.countplot(x=y, data=df_hepatite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ced7f3c",
   "metadata": {},
   "source": [
    "## Hold-out\n",
    "\n",
    "Antes de realizar o 10-Fold os dados serão separados em treino e teste através do método **hold-out**. O data set de treino será utilizado para validar os modelos e escolher os melhores parâmetros com o **10-fold** para então comparar o modelos com o data set de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09a37e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=199, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "165c05f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>ALB</th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>BIL</th>\n",
       "      <th>CHE</th>\n",
       "      <th>CHOL</th>\n",
       "      <th>CREA</th>\n",
       "      <th>GGT</th>\n",
       "      <th>PROT</th>\n",
       "      <th>M</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0.571775</td>\n",
       "      <td>1.367389</td>\n",
       "      <td>0.162105</td>\n",
       "      <td>0.717499</td>\n",
       "      <td>-0.152456</td>\n",
       "      <td>-0.236607</td>\n",
       "      <td>3.182436</td>\n",
       "      <td>0.777511</td>\n",
       "      <td>0.513023</td>\n",
       "      <td>0.193720</td>\n",
       "      <td>1.126467</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>-1.831954</td>\n",
       "      <td>-0.151743</td>\n",
       "      <td>-0.991511</td>\n",
       "      <td>-1.188754</td>\n",
       "      <td>1.507277</td>\n",
       "      <td>-0.277105</td>\n",
       "      <td>1.516243</td>\n",
       "      <td>0.038284</td>\n",
       "      <td>-0.529656</td>\n",
       "      <td>1.767583</td>\n",
       "      <td>-1.168353</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>-0.129312</td>\n",
       "      <td>-0.837204</td>\n",
       "      <td>0.957980</td>\n",
       "      <td>0.273965</td>\n",
       "      <td>0.046957</td>\n",
       "      <td>-0.449219</td>\n",
       "      <td>0.708531</td>\n",
       "      <td>1.219244</td>\n",
       "      <td>-0.070716</td>\n",
       "      <td>0.500016</td>\n",
       "      <td>-0.477876</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>-0.930556</td>\n",
       "      <td>0.033517</td>\n",
       "      <td>-1.007590</td>\n",
       "      <td>0.340023</td>\n",
       "      <td>0.240235</td>\n",
       "      <td>-0.413784</td>\n",
       "      <td>-0.971508</td>\n",
       "      <td>-0.574734</td>\n",
       "      <td>0.291605</td>\n",
       "      <td>-0.455475</td>\n",
       "      <td>-1.127736</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>-1.130866</td>\n",
       "      <td>1.311811</td>\n",
       "      <td>0.604258</td>\n",
       "      <td>-0.504579</td>\n",
       "      <td>-0.305851</td>\n",
       "      <td>-0.130301</td>\n",
       "      <td>0.325445</td>\n",
       "      <td>-0.250195</td>\n",
       "      <td>0.311734</td>\n",
       "      <td>-0.451622</td>\n",
       "      <td>1.552938</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>-0.129312</td>\n",
       "      <td>-0.948360</td>\n",
       "      <td>-0.219754</td>\n",
       "      <td>-0.792404</td>\n",
       "      <td>-0.520604</td>\n",
       "      <td>-0.393535</td>\n",
       "      <td>-0.939200</td>\n",
       "      <td>-1.178736</td>\n",
       "      <td>-0.292134</td>\n",
       "      <td>-0.445843</td>\n",
       "      <td>-0.660649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>-0.630089</td>\n",
       "      <td>-0.818678</td>\n",
       "      <td>0.294751</td>\n",
       "      <td>0.019169</td>\n",
       "      <td>-0.265969</td>\n",
       "      <td>-0.373287</td>\n",
       "      <td>1.114695</td>\n",
       "      <td>0.173508</td>\n",
       "      <td>0.029929</td>\n",
       "      <td>-0.378419</td>\n",
       "      <td>-0.071713</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>0.271309</td>\n",
       "      <td>1.070973</td>\n",
       "      <td>0.379162</td>\n",
       "      <td>-0.169569</td>\n",
       "      <td>-0.517536</td>\n",
       "      <td>-0.337851</td>\n",
       "      <td>0.491603</td>\n",
       "      <td>0.930765</td>\n",
       "      <td>-0.090845</td>\n",
       "      <td>-0.326406</td>\n",
       "      <td>0.253217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>1.573329</td>\n",
       "      <td>1.070973</td>\n",
       "      <td>-0.316224</td>\n",
       "      <td>-0.306404</td>\n",
       "      <td>-0.201543</td>\n",
       "      <td>-0.155612</td>\n",
       "      <td>0.477757</td>\n",
       "      <td>0.633271</td>\n",
       "      <td>-0.392779</td>\n",
       "      <td>-0.384198</td>\n",
       "      <td>0.456299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-0.730245</td>\n",
       "      <td>0.589297</td>\n",
       "      <td>0.258575</td>\n",
       "      <td>-0.315841</td>\n",
       "      <td>-0.161660</td>\n",
       "      <td>0.026626</td>\n",
       "      <td>0.413140</td>\n",
       "      <td>0.822586</td>\n",
       "      <td>0.211089</td>\n",
       "      <td>-0.272467</td>\n",
       "      <td>0.375066</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>425 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age       ALB       ALP       ALT       AST       BIL       CHE  \\\n",
       "235  0.571775  1.367389  0.162105  0.717499 -0.152456 -0.236607  3.182436   \n",
       "557 -1.831954 -0.151743 -0.991511 -1.188754  1.507277 -0.277105  1.516243   \n",
       "158 -0.129312 -0.837204  0.957980  0.273965  0.046957 -0.449219  0.708531   \n",
       "76  -0.930556  0.033517 -1.007590  0.340023  0.240235 -0.413784 -0.971508   \n",
       "52  -1.130866  1.311811  0.604258 -0.504579 -0.305851 -0.130301  0.325445   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "407 -0.129312 -0.948360 -0.219754 -0.792404 -0.520604 -0.393535 -0.939200   \n",
       "107 -0.630089 -0.818678  0.294751  0.019169 -0.265969 -0.373287  1.114695   \n",
       "447  0.271309  1.070973  0.379162 -0.169569 -0.517536 -0.337851  0.491603   \n",
       "525  1.573329  1.070973 -0.316224 -0.306404 -0.201543 -0.155612  0.477757   \n",
       "95  -0.730245  0.589297  0.258575 -0.315841 -0.161660  0.026626  0.413140   \n",
       "\n",
       "         CHOL      CREA       GGT      PROT    M    F  \n",
       "235  0.777511  0.513023  0.193720  1.126467  1.0  0.0  \n",
       "557  0.038284 -0.529656  1.767583 -1.168353  1.0  0.0  \n",
       "158  1.219244 -0.070716  0.500016 -0.477876  1.0  0.0  \n",
       "76  -0.574734  0.291605 -0.455475 -1.127736  1.0  0.0  \n",
       "52  -0.250195  0.311734 -0.451622  1.552938  1.0  0.0  \n",
       "..        ...       ...       ...       ...  ...  ...  \n",
       "407 -1.178736 -0.292134 -0.445843 -0.660649  0.0  1.0  \n",
       "107  0.173508  0.029929 -0.378419 -0.071713  1.0  0.0  \n",
       "447  0.930765 -0.090845 -0.326406  0.253217  0.0  1.0  \n",
       "525  0.633271 -0.392779 -0.384198  0.456299  0.0  1.0  \n",
       "95   0.822586  0.211089 -0.272467  0.375066  1.0  0.0  \n",
       "\n",
       "[425 rows x 13 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ab1c87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converte para numpy array\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff943b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    161\n",
       "3      9\n",
       "1      7\n",
       "2      6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_test).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326547bd",
   "metadata": {},
   "source": [
    "# SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06bc361d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nstrategy = {1:1500, 2:1500, 3:1500, 4:1500}\\noversample = SMOTE(sampling_strategy=strategy)\\nX_final, y = oversample.fit_resample(X_final, y)\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "strategy = {1:1500, 2:1500, 3:1500, 4:1500}\n",
    "oversample = SMOTE(sampling_strategy=strategy)\n",
    "X_final, y = oversample.fit_resample(X_final, y)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2c2e8f",
   "metadata": {},
   "source": [
    "## Funções para executar os modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b86d6693",
   "metadata": {},
   "outputs": [],
   "source": [
    "#função que retorna um dicionário com os valores dos resultados\n",
    "def model_results(model, X_train, y_train, X_test, y_test,results_dict_aux):\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # medindo e armazenando acurácia e f1-score no dicionário\n",
    "    # accuracy = model.score(X_test, y_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    # AUC = roc_auc_score(y_test, model.predict_proba(X_test), average='weighted', multi_class='ovo')\n",
    "    CM = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    results_dict_aux['accuracy'].append(accuracy)\n",
    "    results_dict_aux['f1'].append(f1)\n",
    "    #results_dict_aux['auc'].append(AUC)\n",
    "    results_dict_aux['cm'].append(CM)\n",
    "    \n",
    "    #print(f\"f1: %.6f\\n\" %(f1))\n",
    "    #print(f\"Accuracy: %.6f\\n\" %(accuracy))\n",
    "    #print(f\"AUC: %.6f\" %(AUC))\n",
    "    #print(f\"CM: \\n{CM} \\n\")\n",
    "    '''\n",
    "    print(\"-----------------------CURVA ROC---------------------\")\n",
    "    visualizer = ROCAUC(model, encoder={1:\"Class 1\", 2:\"Class 2\", 3:\"Class 3\", 4:\"Class 4\"})\n",
    "\n",
    "    visualizer.fit(X_train, y_train)        \n",
    "    visualizer.score(X_test, y_test)        \n",
    "    visualizer.show()                       \n",
    "    #print(\"-----------------------------------------------------\\n\")'''\n",
    "    \n",
    "    #print (classification_report(y_test, y_pred))\n",
    "    \n",
    "    return results_dict_aux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1fa7c0",
   "metadata": {},
   "source": [
    "## RandomizedSearch\n",
    "\n",
    "Para cada modelo é implementada uma função do RandomizedSearch. Para ser aplicada em cada um dos 10 conjuntos de treino do 10-fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a4ebd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_search(model, param_grid, X, y):\n",
    "\n",
    "    # defining parameter range\n",
    "    grid = RandomizedSearchCV(model, param_grid, cv=3,random_state=199, scoring='accuracy', n_jobs=5)\n",
    "    # fitting the model for grid search\n",
    "    grid.fit(X, y)\n",
    "    #utilizando melhores parâmetros calculados pelo gridsearch\n",
    "    dic_best = grid.best_params_\n",
    "    \n",
    "    return dic_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd15fef",
   "metadata": {},
   "source": [
    "**KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2727b7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dicionário com parêmetros para o gridsearch\n",
    "knn_param_grid = {\n",
    "    'n_neighbors': [impar for impar in range(1,32) if (impar%2)!=0],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidian','manhattan','chebyshev']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1db3ba7",
   "metadata": {},
   "source": [
    "**Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89a5bedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dicionário com parêmetros para o gridsearch\n",
    "dt_param_grid = {\n",
    "    'max_depth': [x for x in range(1,32)],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fce1a4",
   "metadata": {},
   "source": [
    "**MLP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfe9d816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dicionário com parêmetros para o gridsearch\n",
    "mlp_param_grid = {\n",
    "    'hidden_layer_sizes': [(100,), (50, 15, 5), (100, 25, 10)],\n",
    "    'activation': ['tanh', 'relu', 'logistic'],\n",
    "    'solver': ['sgd', 'adam', 'lbfgs'],\n",
    "    'learning_rate': ['constant', 'adaptive'],\n",
    "    'learning_rate_init': [0.1, 0.01, 0.001],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db79b59",
   "metadata": {},
   "source": [
    "**SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0306a680",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dicionário com parêmetros para o gridsearch\n",
    "svm_param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['rbf','sigmoid', 'linear'], #['linear', 'poly', 'rbf', 'sigmoid']\n",
    "    'gamma': [1, 0.1, 0.01, 0.001]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7e82a4",
   "metadata": {},
   "source": [
    "**Regressão Logística Multimodal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "897d5820",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr_param_grid = {\n",
    "    'penalty': ['l2', 'none'],\n",
    "    'solver': ['newton-cg', 'sag', 'lbfgs']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ffbd07",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38edae92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# profundidade máxima\n",
    "max_depth = [int(x) for x in np.linspace(100, 300, num = 11)]\n",
    "max_depth.append(None)\n",
    "# grid\n",
    "rf_param_grid = {\n",
    " 'n_estimators': [int(x) for x in np.linspace(start = 100, stop = 500, num = 10)],\n",
    " 'max_depth': max_depth,\n",
    " # numero de features a serem consideradas em cada fold\n",
    " 'max_features': ['auto', 'sqrt', 'log2']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75482419",
   "metadata": {},
   "source": [
    "**Gradiente Boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb47581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_param_grid = {\n",
    "    \"loss\":[\"deviance\", \"exponential\"],\n",
    "    \"learning_rate\": [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "    \"min_samples_split\": np.linspace(0.1, 0.5, 12),\n",
    "    \"min_samples_leaf\": np.linspace(0.1, 0.5, 12),\n",
    "    \"max_depth\":[3,5,8],\n",
    "    \"max_features\":[\"log2\",\"sqrt\"],\n",
    "    \"criterion\": [\"friedman_mse\",  \"mae\"],\n",
    "    \"subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "    \"n_estimators\":[10]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee7fd4f",
   "metadata": {},
   "source": [
    "**Extreme Gradient Boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0306cd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_param_grid = {\n",
    "    \"objective\": ['multi:softmax'],\n",
    "    \"max_depth\": range (2, 10, 1),\n",
    "    \"n_estimators\": range(60, 220, 40),\n",
    "    \"learning_rate\": [0.1, 0.01, 0.05],\n",
    "    \"subsample\": [0.8],\n",
    "    \"colsample_bytree\": [0.5],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48feb7d2",
   "metadata": {},
   "source": [
    "**Ada Boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a540b93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_param_grid = {\n",
    "    'n_estimators':[int(x) for x in np.linspace(start = 100, stop = 2000, num = 10)],\n",
    "    'learning_rate':[.001,0.01, 0.1, 1, 2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32bbbb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_restults(results_dict_models):    \n",
    "    # a cada interação calcula a média e o desvio padrão da \n",
    "    # acurácia, f1-score e matriz de confusão de cada modelo\n",
    "    for model_key in results_dict_models.keys():\n",
    "        accuracies = np.array(results_dict_models[model_key]['accuracy'])\n",
    "        f1 = np.array(results_dict_models[model_key]['f1'])\n",
    "        #auc = np.array(results_dict_models[model_key]['auc'])\n",
    "        conf_matrix = np.array(results_dict_models[model_key]['cm'])\n",
    "\n",
    "        print_mean_result(model_key, accuracies, f1, conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f954d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_best_results(best_dict_knn, best_dict_dt, best_dict_mlp, best_dict_svm, best_dict_mlr, best_dict_rf, best_dict_xgb, best_dict_gb , best_dict_ab):\n",
    "    print(\"\\n------- BEST PARAMETERS -------\")\n",
    "    print(f\"KNN: {best_dict_knn}\")\n",
    "    print(f\"DT: {best_dict_dt}\")\n",
    "    print(f\"MLP: {best_dict_mlp}\")\n",
    "    print(f\"SVM: {best_dict_svm}\")\n",
    "    print(f\"MLR: {best_dict_mlr}\")\n",
    "    print(f\"RF: {best_dict_rf}\") \n",
    "    print(f\"XGB: dic:{best_dict_xgb}\") \n",
    "    print(f\"GB: dic:{best_dict_gb}\") \n",
    "    print(f\"AB: dic:{best_dict_ab}\")\n",
    "    print(\"--------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2566fbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_mean_result(model_key, accuracies, f1, conf_matrix):\n",
    "    print(f\"\\t{model_key}\")\n",
    "    print(\"Acurácia média (desvio): %.6f +- (%.6f)\" %(accuracies.mean(), accuracies.std()))\n",
    "    print(\"F1-score média (desvio): %.6f +- (%.6f)\" %(f1.mean(), f1.std()))\n",
    "    #print(\"AUC média (desvio): %.6f +- (%.6f)\\n\" %(auc.mean(), auc.std()))\n",
    "    print(f\"Matriz de Confusão:  \\n{sum(conf_matrix)*0.1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6c3650",
   "metadata": {},
   "source": [
    "## 10-Fold\n",
    "\n",
    "Com esse método são criados 10 datasets de treino e 10 datasets de test com uma divisão de 90% para treino e 10% para teste em cada divisão.\n",
    "\n",
    "O conjunto de treino sera divido mais uma vez em treino e validação (isso é feito dendo da função `GridSearchCV` para que então seja aplicado o GridSearch e assim obtenha-se os melhores parâmetros. Por fim, tendo os melhores parâmetros, utiliza-se o conjunto de teste para que se possa avaliar os resultados.\n",
    "\n",
    "Esses resultados são obtidos de cada fold e então se tira a média deles para obter-se a avaliação final de cada modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac1b239d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#função que roda os modelos em cada uma das divisões do 10-fold\n",
    "#e imprime a média e o desvio padrão dos resultados\n",
    "\n",
    "def evaluate_model_with_kfold(kf):\n",
    "    results_dict_models = {}\n",
    "    # listas e dicionarios para salvar as métricas dos resultados de todas as interacoes\n",
    "    # a key 'best'salva a melhor acurácia\n",
    "    \n",
    "    results_dict_KNN = {\n",
    "        'accuracy': [],\n",
    "        'f1': [],\n",
    "        #'auc': [],\n",
    "        'cm': [],\n",
    "        'best': 0.0\n",
    "    }\n",
    "    \n",
    "    results_dict_PERC = {\n",
    "        'accuracy': [], 'f1': [],  'cm': [], 'best': 0.0\n",
    "    }\n",
    "    results_dict_DT = {\n",
    "        'accuracy': [], 'f1': [],  'cm': [], 'best': 0.0\n",
    "    }\n",
    "    results_dict_MLP = {\n",
    "        'accuracy': [], 'f1': [],  'cm': [], 'best': 0.0\n",
    "    }\n",
    "    results_dict_SVM = {\n",
    "        'accuracy': [], 'f1': [],  'cm': [], 'best': 0.0\n",
    "    }\n",
    "    results_dict_GNB = {\n",
    "        'accuracy': [], 'f1': [],  'cm': [], 'best': 0.0\n",
    "    }\n",
    "    results_dict_MLR = {\n",
    "        'accuracy': [], 'f1': [],  'cm': [], 'best': 0.0\n",
    "    }\n",
    "    results_dict_RF = {\n",
    "        'accuracy': [], 'f1': [],  'cm': [], 'best': 0.0\n",
    "    }\n",
    "    results_dict_XGB = {\n",
    "        'accuracy': [], 'f1': [],  'cm': [], 'best': 0.0\n",
    "    }\n",
    "    results_dict_GB = {\n",
    "        'accuracy': [], 'f1': [],  'cm': [], 'best': 0.0\n",
    "    }\n",
    "    results_dict_AB = {\n",
    "        'accuracy': [], 'f1': [],  'cm': [], 'best': 0.0\n",
    "    }\n",
    "\n",
    "    \n",
    "    # váriável para salvar os melhores parâmetros\n",
    "    best_dict_knn, best_dict_dt, best_dict_mlp, best_dict_svm, best_dict_mlr, best_dict_rf, best_dict_xgb, best_dict_gb , best_dict_ab = {}, {}, {}, {}, {}, {}, {}, {}, {}\n",
    "    \n",
    "    fold = 0\n",
    "    \n",
    "    # laço que roda todos os modelos em cada 1-fold\n",
    "    for train, test in kf.split(X_train, y_train):\n",
    "    \n",
    "        # usa a lista retornada pelo .split para selicionar as intâncias de cada fold\n",
    "        X_train_kf = X_train[train,:] \n",
    "        y_train_kf = y_train[train]\n",
    "        X_test_kf = X_train[test,:]\n",
    "        y_test_kf = y_train[test]\n",
    "        \n",
    "        # para acompanhar a execução \n",
    "        fold += 1\n",
    "        print(f\"\\n{fold}º fold\")\n",
    "        \n",
    "        #kNN\n",
    "        print(\"-KNN\")\n",
    "        dict_knn = Random_search(knn(), knn_param_grid, X_train_kf, y_train_kf)\n",
    "        model = knn(**dict_knn)\n",
    "        results_dict_KNN = model_results(model, X_train_kf, y_train_kf, X_test_kf, y_test_kf, results_dict_KNN)\n",
    "        #verifica se os parêmetros do fold atual são os melhores\n",
    "        if (results_dict_KNN['accuracy'][-1] > results_dict_KNN['best']): \n",
    "            results_dict_KNN['best'] = results_dict_KNN['accuracy'][-1]\n",
    "            best_dict_knn = dict_knn \n",
    "            \n",
    "        #PerC\n",
    "        print(\"-PerC\")\n",
    "        model = PerC()\n",
    "        results_dict_PERC = model_results(model, X_train_kf, y_train_kf, X_test_kf, y_test_kf, results_dict_PERC)\n",
    "            \n",
    "        #DT\n",
    "        print(\"-DT\")\n",
    "        dict_dt = Random_search(DecisionTreeClassifier(), dt_param_grid, X_train_kf, y_train_kf)\n",
    "        model = DecisionTreeClassifier(**dict_dt, random_state=199)\n",
    "        results_dict_DT = model_results(model, X_train_kf, y_train_kf, X_test_kf, y_test_kf, results_dict_DT)\n",
    "        #verifica se os parêmetros do fold atual são os melhores\n",
    "        if (results_dict_DT['accuracy'][-1] > results_dict_DT['best']): \n",
    "            results_dict_DT['best'] = results_dict_DT['accuracy'][-1]\n",
    "            best_dict_dt = dict_dt\n",
    "        \n",
    "        \n",
    "        #MLP \n",
    "        print(\"-MLP\")\n",
    "        dict_mlp = Random_search(MLPClassifier(),mlp_param_grid, X_train_kf,y_train_kf)\n",
    "        model = MLPClassifier(**dict_mlp, max_iter=2000, tol=0.000001, random_state=199)\n",
    "        results_dict_MLP = model_results(model, X_train_kf, y_train_kf, X_test_kf, y_test_kf, results_dict_MLP)\n",
    "        #verifica se os parêmetros do fold atual são os melhores comparando a acurácia\n",
    "        if (results_dict_MLP['accuracy'][-1] > results_dict_MLP['best']): \n",
    "            results_dict_MLP['best'] = results_dict_MLP['accuracy'][-1]\n",
    "            best_dict_mlp = dict_mlp\n",
    "        \n",
    "        #GNB \n",
    "        print(\"-GNB\")\n",
    "        model = GaussianNB()\n",
    "        results_dict_models['GNB'] = model_results(model, X_train_kf, y_train_kf, X_test_kf, y_test_kf, results_dict_GNB)\n",
    "        \n",
    "        #SVM\n",
    "        print(\"-SVM\")\n",
    "        dict_svm = Random_search(SVC(), svm_param_grid, X_train_kf, y_train_kf)\n",
    "        model = SVC(**dict_svm, probability=True, random_state=199)\n",
    "        results_dict_SVM = model_results(model, X_train_kf, y_train_kf, X_test_kf, y_test_kf, results_dict_SVM)\n",
    "        #verifica se os parêmetros do fold atual são os melhores\n",
    "        if (results_dict_SVM['accuracy'][-1] > results_dict_SVM['best']): \n",
    "            results_dict_SVM['best'] = results_dict_SVM['accuracy'][-1]\n",
    "            best_dict_svm = dict_svm           \n",
    "        \n",
    "        # Regressão Logística Multimodal\n",
    "        print(\"-MLR\")\n",
    "        dict_mlr = Random_search(LogisticRegression(), mlr_param_grid, X_train_kf, y_train_kf)\n",
    "        model = LogisticRegression(**dict_mlr, multi_class='multinomial', random_state=199)\n",
    "        results_dict_MLR = model_results(model, X_train_kf, y_train_kf, X_test_kf, y_test_kf, results_dict_MLR)\n",
    "        #verifica se os parêmetros do fold atual são os melhores\n",
    "        if (results_dict_MLR['accuracy'][-1] > results_dict_MLR['best']): \n",
    "            results_dict_MLR['best'] = results_dict_MLR['accuracy'][-1]\n",
    "            best_dict_mlr = dict_mlr \n",
    "        \n",
    "        # Random Forest\n",
    "        print(\"-RF\")\n",
    "        dict_rf = Random_search(RandomForestClassifier(), rf_param_grid, X_train_kf, y_train_kf)\n",
    "        model = RandomForestClassifier(**dict_rf, random_state=199)\n",
    "        results_dict_RF = model_results(model, X_train_kf, y_train_kf, X_test_kf, y_test_kf, results_dict_RF)\n",
    "        #verifica se os parêmetros do fold atual são os melhores\n",
    "        if (results_dict_RF['accuracy'][-1] > results_dict_RF['best']): \n",
    "            results_dict_RF['best'] = results_dict_RF['accuracy'][-1]\n",
    "            best_dict_rf = dict_rf \n",
    "      \n",
    "        # Ada Boosting\n",
    "        print(\"-AB\")\n",
    "        dict_ab = Random_search(AdaBoostClassifier(), ab_param_grid, X_train_kf, y_train_kf)\n",
    "        model = AdaBoostClassifier(**dict_ab, random_state=199)\n",
    "        results_dict_AB = model_results(model, X_train_kf, y_train_kf, X_test_kf, y_test_kf, results_dict_AB)\n",
    "        #verifica se os parêmetros do fold atual são os melhores\n",
    "        if (results_dict_AB['accuracy'][-1] > results_dict_AB['best']): \n",
    "            results_dict_AB['best'] = results_dict_AB['accuracy'][-1]\n",
    "            best_dict_ab = dict_ab\n",
    "      \n",
    "        # EXtrem Gradiente Boosting\n",
    "        print(\"-XGB\")\n",
    "        dict_xgb = Random_search(XGBClassifier(), xgb_param_grid, X_train_kf, y_train_kf)\n",
    "        model = XGBClassifier(**dict_xgb, random_state=199)\n",
    "        results_dict_XGB = model_results(model, X_train_kf, y_train_kf, X_test_kf, y_test_kf, results_dict_XGB)\n",
    "        #verifica se os parêmetros do fold atual são os melhores\n",
    "        if (results_dict_XGB['accuracy'][-1] > results_dict_XGB['best']): \n",
    "            results_dict_XGB['best'] = results_dict_XGB['accuracy'][-1]\n",
    "            best_dict_xgb = dict_xgb\n",
    "      \n",
    "        # GB\n",
    "        print(\"-GB\")\n",
    "        dict_gb = Random_search(GradientBoostingClassifier(), gb_param_grid, X_train_kf, y_train_kf)\n",
    "        model = GradientBoostingClassifier(**dict_gb, random_state=199)\n",
    "        results_dict_GB = model_results(model, X_train_kf, y_train_kf, X_test_kf, y_test_kf, results_dict_GB)\n",
    "        #verifica se os parêmetros do fold atual são os melhores\n",
    "        if (results_dict_GB['accuracy'][-1] > results_dict_GB['best']): \n",
    "            results_dict_GB['best'] = results_dict_GB['accuracy'][-1]\n",
    "            best_dict_gb = dict_gb        \n",
    "        \n",
    "    results_dict_models['KNN'] = results_dict_KNN\n",
    "    results_dict_models['DT'] = results_dict_DT\n",
    "    results_dict_models['MLP'] = results_dict_MLP\n",
    "    results_dict_models['GNB'] = results_dict_GNB\n",
    "    results_dict_models['SVM'] = results_dict_SVM\n",
    "    results_dict_models['MLR'] = results_dict_MLR\n",
    "    results_dict_models['RF'] = results_dict_RF\n",
    "    results_dict_models['XGB'] = results_dict_XGB\n",
    "    results_dict_models['GB'] = results_dict_GB\n",
    "    results_dict_models['AB'] = results_dict_AB\n",
    "    results_dict_models['PERC'] = results_dict_PERC\n",
    "    \n",
    "    # calcula a média dos resultados e imprime cada métrica\n",
    "    calculate_mean_restults(results_dict_models)\n",
    "\n",
    "    # imprime os melhores parâmetros\n",
    "    print_best_results(best_dict_knn, best_dict_dt, best_dict_mlp, best_dict_svm, best_dict_mlr, best_dict_rf, best_dict_xgb, best_dict_ab, best_dict_gb)\n",
    "    \n",
    "    # salva os melhores parâmetros em um dicionário que é o retorno da função\n",
    "    parameters_dict = {\n",
    "        'knn': best_dict_knn,\n",
    "        'dt': best_dict_dt,\n",
    "        'mlp': best_dict_mlp,\n",
    "        'svm': best_dict_svm,\n",
    "        'mlr': best_dict_mlr,\n",
    "        'rf': best_dict_rf,\n",
    "        'xgb': best_dict_xgb,\n",
    "        'gb': best_dict_gb,\n",
    "        'ab': best_dict_ab\n",
    "    }\n",
    "    \n",
    "    return parameters_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a49a09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c1d9f383",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1º fold\n",
      "-KNN\n",
      "-PerC\n",
      "-DT\n",
      "-MLP\n",
      "-GNB\n",
      "-SVM\n",
      "-MLR\n",
      "-RF\n",
      "-AB\n",
      "-XGB\n",
      "[20:00:25] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:00:25] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "-GB\n",
      "\n",
      "2º fold\n",
      "-KNN\n",
      "-PerC\n",
      "-DT\n",
      "-MLP\n",
      "-GNB\n",
      "-SVM\n",
      "-MLR\n",
      "-RF\n",
      "-AB\n",
      "-XGB\n",
      "[20:01:32] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:01:33] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "-GB\n",
      "\n",
      "3º fold\n",
      "-KNN\n",
      "-PerC\n",
      "-DT\n",
      "-MLP\n",
      "-GNB\n",
      "-SVM\n",
      "-MLR\n",
      "-RF\n",
      "-AB\n",
      "-XGB\n",
      "[20:02:40] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:02:40] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "-GB\n",
      "\n",
      "4º fold\n",
      "-KNN\n",
      "-PerC\n",
      "-DT\n",
      "-MLP\n",
      "-GNB\n",
      "-SVM\n",
      "-MLR\n",
      "-RF\n",
      "-AB\n",
      "-XGB\n",
      "[20:03:45] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:03:46] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "-GB\n",
      "\n",
      "5º fold\n",
      "-KNN\n",
      "-PerC\n",
      "-DT\n",
      "-MLP\n",
      "-GNB\n",
      "-SVM\n",
      "-MLR\n",
      "-RF\n",
      "-AB\n",
      "-XGB\n",
      "[20:04:58] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:04:59] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "-GB\n",
      "\n",
      "6º fold\n",
      "-KNN\n",
      "-PerC\n",
      "-DT\n",
      "-MLP\n",
      "-GNB\n",
      "-SVM\n",
      "-MLR\n",
      "-RF\n",
      "-AB\n",
      "-XGB\n",
      "[20:06:04] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:06:05] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "-GB\n",
      "\n",
      "7º fold\n",
      "-KNN\n",
      "-PerC\n",
      "-DT\n",
      "-MLP\n",
      "-GNB\n",
      "-SVM\n",
      "-MLR\n",
      "-RF\n",
      "-AB\n",
      "-XGB\n",
      "[20:07:04] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:07:04] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "-GB\n",
      "\n",
      "8º fold\n",
      "-KNN\n",
      "-PerC\n",
      "-DT\n",
      "-MLP\n",
      "-GNB\n",
      "-SVM\n",
      "-MLR\n",
      "-RF\n",
      "-AB\n",
      "-XGB\n",
      "[20:08:15] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:08:16] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "-GB\n",
      "\n",
      "9º fold\n",
      "-KNN\n",
      "-PerC\n",
      "-DT\n",
      "-MLP\n",
      "-GNB\n",
      "-SVM\n",
      "-MLR\n",
      "-RF\n",
      "-AB\n",
      "-XGB\n",
      "[20:09:19] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:09:19] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "-GB\n",
      "\n",
      "10º fold\n",
      "-KNN\n",
      "-PerC\n",
      "-DT\n",
      "-MLP\n",
      "-GNB\n",
      "-SVM\n",
      "-MLR\n",
      "-RF\n",
      "-AB\n",
      "-XGB\n",
      "[20:10:25] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:10:26] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "-GB\n",
      "\tGNB\n",
      "Acurácia média (desvio): 0.908306 +- (0.035716)\n",
      "F1-score média (desvio): 0.910008 +- (0.025599)\n",
      "Matriz de Confusão:  \n",
      "[[35.6  0.5  0.7  0.4]\n",
      " [ 0.8  0.5  0.3  0.1]\n",
      " [ 0.1  0.7  0.7  0. ]\n",
      " [ 0.   0.   0.3  1.8]]\n",
      "\tKNN\n",
      "Acurácia média (desvio): 0.913012 +- (0.020711)\n",
      "F1-score média (desvio): 0.892594 +- (0.024678)\n",
      "Matriz de Confusão:  \n",
      "[[36.8  0.2  0.1  0.1]\n",
      " [ 1.3  0.2  0.1  0.1]\n",
      " [ 0.7  0.2  0.5  0.1]\n",
      " [ 0.6  0.   0.2  1.3]]\n",
      "\tDT\n",
      "Acurácia média (desvio): 0.891971 +- (0.047892)\n",
      "F1-score média (desvio): 0.890029 +- (0.031610)\n",
      "Matriz de Confusão:  \n",
      "[[35.8  0.6  0.6  0.2]\n",
      " [ 0.9  0.1  0.5  0.2]\n",
      " [ 0.   0.4  0.8  0.3]\n",
      " [ 0.3  0.   0.6  1.2]]\n",
      "\tMLP\n",
      "Acurácia média (desvio): 0.938926 +- (0.018506)\n",
      "F1-score média (desvio): 0.932292 +- (0.025326)\n",
      "Matriz de Confusão:  \n",
      "[[36.3  0.5  0.2  0.2]\n",
      " [ 0.5  0.9  0.3  0. ]\n",
      " [ 0.2  0.4  0.9  0. ]\n",
      " [ 0.2  0.   0.1  1.8]]\n",
      "\tSVM\n",
      "Acurácia média (desvio): 0.924806 +- (0.013526)\n",
      "F1-score média (desvio): 0.911914 +- (0.018401)\n",
      "Matriz de Confusão:  \n",
      "[[36.5  0.4  0.1  0.2]\n",
      " [ 0.8  0.7  0.2  0. ]\n",
      " [ 0.3  0.4  0.5  0.3]\n",
      " [ 0.4  0.   0.1  1.6]]\n",
      "\tMLR\n",
      "Acurácia média (desvio): 0.948173 +- (0.025447)\n",
      "F1-score média (desvio): 0.935479 +- (0.030370)\n",
      "Matriz de Confusão:  \n",
      "[[37.1  0.   0.1  0. ]\n",
      " [ 0.8  0.7  0.2  0. ]\n",
      " [ 0.3  0.4  0.6  0.2]\n",
      " [ 0.2  0.   0.   1.9]]\n",
      "\tRF\n",
      "Acurácia média (desvio): 0.920155 +- (0.027660)\n",
      "F1-score média (desvio): 0.905815 +- (0.022335)\n",
      "Matriz de Confusão:  \n",
      "[[36.6  0.4  0.1  0.1]\n",
      " [ 1.   0.3  0.4  0. ]\n",
      " [ 0.4  0.5  0.5  0.1]\n",
      " [ 0.4  0.   0.   1.7]]\n",
      "\tXGB\n",
      "Acurácia média (desvio): 0.934164 +- (0.017465)\n",
      "F1-score média (desvio): 0.916469 +- (0.022863)\n",
      "Matriz de Confusão:  \n",
      "[[37.2  0.   0.   0. ]\n",
      " [ 1.   0.4  0.3  0. ]\n",
      " [ 0.4  0.5  0.5  0.1]\n",
      " [ 0.5  0.   0.   1.6]]\n",
      "\tGB\n",
      "Acurácia média (desvio): 0.875360 +- (0.009807)\n",
      "F1-score média (desvio): 0.817211 +- (0.014012)\n",
      "Matriz de Confusão:  \n",
      "[[37.2  0.   0.   0. ]\n",
      " [ 1.7  0.   0.   0. ]\n",
      " [ 1.5  0.   0.   0. ]\n",
      " [ 2.1  0.   0.   0. ]]\n",
      "\tAB\n",
      "Acurácia média (desvio): 0.894297 +- (0.054819)\n",
      "F1-score média (desvio): 0.894232 +- (0.040071)\n",
      "Matriz de Confusão:  \n",
      "[[35.5  0.8  0.6  0.3]\n",
      " [ 0.7  0.4  0.5  0.1]\n",
      " [ 0.3  0.3  0.8  0.1]\n",
      " [ 0.2  0.3  0.3  1.3]]\n",
      "\tPERC\n",
      "Acurácia média (desvio): 0.913012 +- (0.023176)\n",
      "F1-score média (desvio): 0.876659 +- (0.026884)\n",
      "Matriz de Confusão:  \n",
      "[[37.1  0.   0.   0.1]\n",
      " [ 1.6  0.   0.   0.1]\n",
      " [ 1.4  0.   0.   0.1]\n",
      " [ 0.4  0.   0.   1.7]]\n",
      "\n",
      "------- BEST PARAMETERS -------\n",
      "KNN: {'weights': 'uniform', 'n_neighbors': 1, 'metric': 'chebyshev'}\n",
      "DT: {'max_depth': 17, 'criterion': 'gini'}\n",
      "MLP: {'solver': 'sgd', 'learning_rate_init': 0.01, 'learning_rate': 'constant', 'hidden_layer_sizes': (100, 25, 10), 'activation': 'tanh'}\n",
      "SVM: {'kernel': 'rbf', 'gamma': 0.1, 'C': 100}\n",
      "MLR: {'solver': 'newton-cg', 'penalty': 'l2'}\n",
      "RF: {'n_estimators': 188, 'max_features': 'log2', 'max_depth': None}\n",
      "XGB: dic:{'subsample': 0.8, 'objective': 'multi:softmax', 'n_estimators': 100, 'max_depth': 8, 'learning_rate': 0.1, 'colsample_bytree': 0.5}\n",
      "GB: dic:{'n_estimators': 1366, 'learning_rate': 2}\n",
      "AB: dic:{'subsample': 0.95, 'n_estimators': 10, 'min_samples_split': 0.13636363636363638, 'min_samples_leaf': 0.46363636363636374, 'max_features': 'sqrt', 'max_depth': 5, 'loss': 'deviance', 'learning_rate': 0.05, 'criterion': 'friedman_mse'}\n",
      "--------------------------------------------------------------------------\n",
      "Wall time: 11min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#ignorando warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "params_dict = {}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=199)\n",
    "params_dict = evaluate_model_with_kfold(skf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1388b0d6",
   "metadata": {},
   "source": [
    "## Teste\n",
    "\n",
    "Aqui os modelos são execultados no dataset de teste com seus melhores parâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "443a0783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_test_results(model, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    #medindo e armazenando acurácia e f1-score no dicionário\n",
    "    \n",
    "    #accuracy = model.score(X_test, y_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    #AUC = roc_auc_score(y_test, model.predict_proba(X_test), average='weighted', multi_class='ovo')\n",
    "    CM = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Accuracy: %.6f\" %(accuracy))\n",
    "    print(f\"f1: %.6f\" %(f1))\n",
    "    #print(f\"AUC: %.6f\" %(AUC))\n",
    "    print(f\"CM: \\n{CM} \\n\")\n",
    "    \n",
    "    print (classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7671774",
   "metadata": {},
   "source": [
    "**KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "68cac40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param_dict = params_dict['knn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bfdae165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.912568\n",
      "f1: 0.897352\n",
      "CM: \n",
      "[[160   1   0   0]\n",
      " [  2   2   1   2]\n",
      " [  5   0   0   1]\n",
      " [  2   0   2   5]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       161\n",
      "           1       0.67      0.29      0.40         7\n",
      "           2       0.00      0.00      0.00         6\n",
      "           3       0.62      0.56      0.59         9\n",
      "\n",
      "    accuracy                           0.91       183\n",
      "   macro avg       0.56      0.46      0.49       183\n",
      "weighted avg       0.89      0.91      0.90       183\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = knn(**best_param_dict)\n",
    "model_test_results(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9535ad63",
   "metadata": {},
   "source": [
    "**PerC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "71c9d59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.912568\n",
      "f1: 0.885941\n",
      "CM: \n",
      "[[161   0   0   0]\n",
      " [  3   1   1   2]\n",
      " [  6   0   0   0]\n",
      " [  4   0   0   5]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96       161\n",
      "           1       1.00      0.14      0.25         7\n",
      "           2       0.00      0.00      0.00         6\n",
      "           3       0.71      0.56      0.63         9\n",
      "\n",
      "    accuracy                           0.91       183\n",
      "   macro avg       0.66      0.42      0.46       183\n",
      "weighted avg       0.89      0.91      0.89       183\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = PerC()\n",
    "model_test_results(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb04052",
   "metadata": {},
   "source": [
    "**DT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "14fb64c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param_dict = params_dict['dt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "67969391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.928962\n",
      "f1: 0.915684\n",
      "CM: \n",
      "[[160   1   0   0]\n",
      " [  1   2   1   3]\n",
      " [  4   2   0   0]\n",
      " [  0   0   1   8]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       161\n",
      "           1       0.40      0.29      0.33         7\n",
      "           2       0.00      0.00      0.00         6\n",
      "           3       0.73      0.89      0.80         9\n",
      "\n",
      "    accuracy                           0.93       183\n",
      "   macro avg       0.52      0.54      0.53       183\n",
      "weighted avg       0.90      0.93      0.92       183\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(**best_param_dict, random_state=199)\n",
    "model_test_results(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd43bdec",
   "metadata": {},
   "source": [
    "**MLP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "92a3fef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param_dict = params_dict['mlp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3583e806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.923497\n",
      "f1: 0.911096\n",
      "CM: \n",
      "[[160   1   0   0]\n",
      " [  2   2   1   2]\n",
      " [  4   1   0   1]\n",
      " [  0   0   2   7]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98       161\n",
      "           1       0.50      0.29      0.36         7\n",
      "           2       0.00      0.00      0.00         6\n",
      "           3       0.70      0.78      0.74         9\n",
      "\n",
      "    accuracy                           0.92       183\n",
      "   macro avg       0.54      0.51      0.52       183\n",
      "weighted avg       0.90      0.92      0.91       183\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier(\n",
    "            **best_param_dict, \n",
    "            max_iter=2000, \n",
    "            tol=0.000001,\n",
    "            random_state=199\n",
    "        )\n",
    "model_test_results(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06c4997",
   "metadata": {},
   "source": [
    "**GNB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aedcc720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.907104\n",
      "f1: 0.901903\n",
      "CM: \n",
      "[[158   2   1   0]\n",
      " [  1   2   2   2]\n",
      " [  4   2   0   0]\n",
      " [  1   0   2   6]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       161\n",
      "           1       0.33      0.29      0.31         7\n",
      "           2       0.00      0.00      0.00         6\n",
      "           3       0.75      0.67      0.71         9\n",
      "\n",
      "    accuracy                           0.91       183\n",
      "   macro avg       0.51      0.48      0.50       183\n",
      "weighted avg       0.90      0.91      0.90       183\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = GaussianNB()\n",
    "model_test_results(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2f7971",
   "metadata": {},
   "source": [
    "**SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "04099c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param_dict = params_dict['svm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "adf716f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.912568\n",
      "f1: 0.895961\n",
      "CM: \n",
      "[[160   1   0   0]\n",
      " [  2   2   1   2]\n",
      " [  4   1   0   1]\n",
      " [  3   0   1   5]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       161\n",
      "           1       0.50      0.29      0.36         7\n",
      "           2       0.00      0.00      0.00         6\n",
      "           3       0.62      0.56      0.59         9\n",
      "\n",
      "    accuracy                           0.91       183\n",
      "   macro avg       0.52      0.46      0.48       183\n",
      "weighted avg       0.88      0.91      0.90       183\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = SVC(**best_param_dict, probability=True, random_state=199)\n",
    "model_test_results(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7989607",
   "metadata": {},
   "source": [
    "**MLR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "02a9de5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param_dict = params_dict['mlr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "296973e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.928962\n",
      "f1: 0.919665\n",
      "CM: \n",
      "[[161   0   0   0]\n",
      " [  1   2   2   2]\n",
      " [  4   1   1   0]\n",
      " [  1   0   2   6]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       161\n",
      "           1       0.67      0.29      0.40         7\n",
      "           2       0.20      0.17      0.18         6\n",
      "           3       0.75      0.67      0.71         9\n",
      "\n",
      "    accuracy                           0.93       183\n",
      "   macro avg       0.65      0.53      0.57       183\n",
      "weighted avg       0.92      0.93      0.92       183\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(**best_param_dict, multi_class='multinomial', random_state=199)\n",
    "model_test_results(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284fb9d7",
   "metadata": {},
   "source": [
    "**RF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e1655da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param_dict = params_dict['rf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0b646179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.928962\n",
      "f1: 0.914372\n",
      "CM: \n",
      "[[161   0   0   0]\n",
      " [  2   1   2   2]\n",
      " [  4   1   1   0]\n",
      " [  1   0   1   7]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       161\n",
      "           1       0.50      0.14      0.22         7\n",
      "           2       0.25      0.17      0.20         6\n",
      "           3       0.78      0.78      0.78         9\n",
      "\n",
      "    accuracy                           0.93       183\n",
      "   macro avg       0.62      0.52      0.54       183\n",
      "weighted avg       0.91      0.93      0.91       183\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(**best_param_dict, random_state=199)\n",
    "model_test_results(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749f598f",
   "metadata": {},
   "source": [
    "**XGB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e8720d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param_dict = params_dict['xgb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "34a7fe41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:10:43] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 0.928962\n",
      "f1: 0.913224\n",
      "CM: \n",
      "[[161   0   0   0]\n",
      " [  3   2   1   1]\n",
      " [  4   1   0   1]\n",
      " [  0   1   1   7]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       161\n",
      "           1       0.50      0.29      0.36         7\n",
      "           2       0.00      0.00      0.00         6\n",
      "           3       0.78      0.78      0.78         9\n",
      "\n",
      "    accuracy                           0.93       183\n",
      "   macro avg       0.56      0.52      0.53       183\n",
      "weighted avg       0.90      0.93      0.91       183\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(**best_param_dict, random_state=199)\n",
    "model_test_results(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9fb94b",
   "metadata": {},
   "source": [
    "**Gradient Boost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "53a1c153",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param_dict = params_dict['gb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f877b8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.879781\n",
      "f1: 0.823516\n",
      "CM: \n",
      "[[161   0   0   0]\n",
      " [  7   0   0   0]\n",
      " [  6   0   0   0]\n",
      " [  9   0   0   0]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94       161\n",
      "           1       0.00      0.00      0.00         7\n",
      "           2       0.00      0.00      0.00         6\n",
      "           3       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.88       183\n",
      "   macro avg       0.22      0.25      0.23       183\n",
      "weighted avg       0.77      0.88      0.82       183\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier(**best_param_dict, random_state=199)\n",
    "model_test_results(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80a984c",
   "metadata": {},
   "source": [
    "**Ada Boost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cacdad5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param_dict = params_dict['ab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "23060ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.737705\n",
      "f1: 0.784684\n",
      "CM: \n",
      "[[127  24   0  10]\n",
      " [  2   2   0   3]\n",
      " [  3   2   0   1]\n",
      " [  1   1   1   6]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.79      0.86       161\n",
      "           1       0.07      0.29      0.11         7\n",
      "           2       0.00      0.00      0.00         6\n",
      "           3       0.30      0.67      0.41         9\n",
      "\n",
      "    accuracy                           0.74       183\n",
      "   macro avg       0.33      0.44      0.35       183\n",
      "weighted avg       0.86      0.74      0.78       183\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = AdaBoostClassifier(**best_param_dict, random_state=199)\n",
    "model_test_results(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34cb21e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
